---
title: "Project 1"
format: html
editor: visual
---

```{r}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.path = "plots/")
```

# Part 1

Next-Generation Sequencing (NGS) entails several high-throughput techniques that
generate a big amount of data. The main two approaches involve long-read
sequencing with Nanopore technology and short-read sequencing with an Illumina
machine. In the latter case, Polymerase Chain Reaction (PCR) is performed by the
sequencer to amplify the library and quantify gene expression.

In the ideal situation, we would expect to have a doubling of each RNA strand in
a linear fashion, so that each molecule is duplicated and the ratio between the
expression levels of the different genes is maintained. However, this process
introduces different types of errors due to factors such as the the composition
of the sequence (for example high fraction of G or C) or the secondary
structure, stochasticity and mutation that make it impossible to deduce the
absolute gene expression, especially for low-copy genes.

In addition, the sequencing process involves breaking the mRNA sequence into
several pieces because the machine cannot sequence a full-length genome. Thus,
multiple variants may originate from the same sequence, so we may think there
are several copies of the same gene, but in reality it is one broken copy.
Therefore, we may infer a wrong expression level. Instead, sequencing data
provides a compositional measure of gene expression, where every observation (or
gene) is quantified in relation to the rest of the pool. Thus, it is essential
to normalise reads from different samples when drawing between-sample
comparisons.

# Part 2

The package with the data of interest is imported.

```{r}
# Import package
library(pasilla)
```

RNA-Seq data from Drosophila melanogaster is loaded from the package.

```{r}
# Load data
pasCts <- system.file("extdata", "pasilla_gene_counts.tsv",
                      package = "pasilla", mustWork = TRUE)

pasAnno <- system.file("extdata", "pasilla_sample_annotation.csv",
                       package="pasilla", mustWork = TRUE)

cts <- as.matrix(read.csv(pasCts, sep = "\t", row.names = "gene_id"))

coldata <- read.csv(pasAnno, row.names = 1)
coldata <- coldata[ , c("condition", "type")]

rownames(coldata) <- sub("fb", "", rownames(coldata))
cts <- cts[, rownames(coldata)]
```

The matrix `cts` contains the gene expression data in terms of the number of
reads for `r nrow(cts)` genes from `r ncol(cts)` samples.

```{r}
# View head of counts assay
head(cts, 10)
```

Dimensions of the counts assay can be retrieved with the `dim` function.

```{r}
# Store assay dimensions
mat_dim <- dim(cts)
# View assay dimensions
mat_dim
```

Samples differ from one another in the library size. Therefore, read counts
should be normalised.

```{r}
# View raw library sizes
colSums(cts)
```

Normalisation is performed by dividing the reads from every sample by the
corresponding library size and multiplying by the library size of the first
sample.

```{r}
# Normalise all samples to library size of first sample
norm_cts <- apply(cts, 2, function(col) col / sum(col) * sum(cts[ , 1]))
# Check normalised library sizes
colSums(norm_cts)
```

# Part 3

A function to compute log means an variances for every feature in an assay is
defined below, so that the same workflow can be applied both to untreated and
treated samples.

```{r}
# Define function to compute feature-wise log means and vars
find_log_stats <- function(assay, na.rm = FALSE, pseudocount = 1) {
  
  # Compute row means and vars
  gene_means <- rowMeans(assay, na.rm = na.rm)
  gene_vars <- rowVars(assay, na.rm = na.rm)

  # Take log of means and vars with pseudocount
  gene_log_means <- log(gene_means + pseudocount)
  gene_log_vars <- log(gene_vars + pseudocount)

  # Combine data into a data.frame
  df <- data.frame(Var = gene_log_vars, Mean = gene_log_means)
  return(df)
}
```

The log statistics of the genes from the untreated samples are computed.

```{r}
# Subset data to untreated samples
control_cts <- norm_cts[ , grep("^untreated", colnames(norm_cts))]
# Find log means and vars for genes in control samples
control_stats <- find_log_stats(control_cts)
```

The Poisson distribution fits the data relatively well for lower numbers of
reads, but it creates bias for higher numbers of reads where the variance
becomes larger than the mean. Such phenomenon is called *overdispersion*.

```{r}
# Visualise fit of Poisson distribution to data
plot(control_stats$Mean, control_stats$Var, xlab = "Log Means", ylab = "Log Vars")
abline(a = 0, b = 1, col = "red")
legend("topleft", "Poisson Fit", lty = 1, col = "red")
```

The dispersion coefficient of the negative binomial distribution can be
determined by fitting the corresponding mean-variance relationship to the data.

```{r}
# Fit dispersion coefficient of negative binomial distribution to data
nls_fit <- nls(Var ~ Mean + a * Mean^2, data = control_stats, start = list(a = 0))
summary(nls_fit)
```

Unlike the Poisson distribution, the negative binomial distribution fits well
the data both for lower and higher numbers of reads.

```{r}
# Define var-mean relationship of negative binomial distribution
disper_coef <- summary(nls_fit)$coefficients["a", "Estimate"]
neg_binom <- function(x) x + disper_coef * x^2

# Visualise fit of negative binomial distribution to data
plot(control_stats$Mean, control_stats$Var, xlab = "Log Means", ylab = "Log Vars")
curve(neg_binom, col = "red", add = TRUE)
legend("topleft", "Negative Binomial Fit", lty = 1, col = "red")
```

The same pipeline is applied to the genes from the treated samples.

```{r}
# Subset data to treated samples
treated_cts <- norm_cts[ , grep("^treated", colnames(norm_cts))]
# Find log means and vars for genes in treated samples
treated_stats <- find_log_stats(treated_cts)
```

```{r}
# Visualise fit of Poisson distribution to data
plot(control_stats$Mean, treated_stats$Var, xlab = "Log Means", ylab = "Log Vars")
abline(a = 0, b = 1, col = "red")
legend("topleft", "Poisson Fit", lty = 1, col = "red")
```

```{r}
# Fit dispersion coefficient of negative binomial distribution to data
nls_fit <- nls(Var ~ Mean + a * Mean^2, data = treated_stats, start = list(a = 0))
summary(nls_fit)
```

```{r}
# Define var-mean relationship of negative binomial distribution
disper_coef <- summary(nls_fit)$coefficients["a", "Estimate"]
neg_binom <- function(x) x + disper_coef * x^2

# Visualise fit of negative binomial distribution to data
plot(treated_stats$Mean, treated_stats$Var, xlab = "Log Means", ylab = "Log Vars")
curve(neg_binom, col = "red", add = TRUE)
legend("topleft", "Negative Binomial Fit", lty = 1, col = "red")
```

Judging by our results, we can estimate that the different untreated and treated
samples in this experiment are biological repeats, because these changes are
represented by a greater variability that corresponds to a negative binomial
distribution and less to a Poisson distribution, this is due to the variability
that exists between different animals/tissues. As we can see, our distribution
also better fits a negative binomial distribution.

# Part 4

```{r}
log_cts <- log(norm_cts + 1)
```

```{r}
plot(log_cts[ , "untreated1"], log_cts[ , "treated1"])
grid()
```

```{r}
# Identify gene that is expressed more in treated samples
control_cond <- control_stats$Mean > 8.5 & control_stats$Mean < 9.5
treated_cond <- treated_stats$Mean > 10 & treated_stats$Mean < 11

gene1 <- rownames(norm_cts)[control_cond & treated_cond]
gene1
```

```{r}
# Identify gene that is expressed more in untreated samples
control_cond <- control_stats$Mean > 7 & control_stats$Mean < 8
treated_cond <- treated_stats$Mean > 4 & treated_stats$Mean < 5

gene2 <- rownames(norm_cts)[control_cond & treated_cond]
gene2
```

The expression of `r gene2` shows consistent differences between the control and
treated conditions.

```{r}
plot(log_cts[gene2, ], ylab = "Log Expression")
title(gene2)
```

Our data fit the basic assumptions of DEseq, as it based on negative binomial
distribution.

```{r}
library(DESeq2)
```

```{r}
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design = ~ condition)

dds <- DESeq(dds)
res <- results(dds)

res
```

Curiously, `r gene2` was designated as the most differentially expressed gene by
DESeq2 (effect size: `r signif(res[gene2, "log2FoldChange"], 3)`, p-value:
`r signif(res[gene2, "padj"], digits = 3)`), whereas `r gene1` did not appear
among the top 10 genes but showed statistical significance (effect size:
`r signif(res[gene1, "log2FoldChange"], 3)`, p-value:
`r signif(res[gene1, "padj"], digits = 3)`).

```{r}
sorted_res <- res[order(res$padj), c("log2FoldChange", "padj")]
head(sorted_res, 10)
```

# Part 5

The circadian RNA-Seq data from Zebrafish is imported and processed into a matrix with unique rownames.

```{r}
circ_df <- read.csv("data/CircadianRNAseq.csv")
rownames(circ_df) <- make.unique(circ_df$GeneSymbol)
circ_df[ , c("RefSeqID", "GeneSymbol")] <- NULL
circ_mat <- as.matrix(circ_df)
```

The last five rows (or genes) of the assay are printed below. From the colnames, it can be deduced that samples were collected from 11 PM until 7 PM for two consecutive days, with a time interval of 4 hours.

```{r}
tail(circ_mat, 5)
```

The expression of the per1a gene shows a rather consistent periodicity of 24 hours over the two days of sampling. Such observation agrees with the literature, as per1a is one of the genes responsible for the circadian rhythm of insects as well as mammals, where it is mostly expressed in the area of the brain known as suprachiasmatic nucleus (SPN).

```{r}
plot(circ_mat["per1a", ], ylab = "Norm Expression", type = "b", xaxt = "n")
axis(1, at = 1:12, labels = colnames(circ_mat)) 
```

```{r}
powers <- fft(circ_mat["per1a", ])
powers <- as.numeric(powers * Conj(powers))[2:(1 + length(powers) / 2)]
norm_powers <- powers / sum(powers)
```

```{r}
t <- 4
min_freq <- 1 / (ncol(circ_mat) * t)
max_freq <- 1 / (2 * t)

freq_range <- seq(from = min_freq, to = max_freq, by = min_freq)
```

```{r}
plot(freq_range, norm_powers, xlab = "Frequency in 1/h", ylab = "Norm Power")
```

Between the options of (a) designing an experiment with (a) a higher time
resolution or (b) a longer duration, I believe that option (a) is preferred,
because this can yield a more accurate estimate of the frequency components of
the signal. Instead, option (b) provide relatively little new information, as
the current design already seems to identify the main frequency components
rather well, and a longer duration is unlikely to find more of them.

Frequency analysis represents a more powerful tool than time analysis to detect
the oscillatory nature of biological signals. Because signals are almost
always composed by several waves with different sub-frequencies and mixed up
with noise, it is not practical to study their oscillatory nature in the time
domain. Instead, the frequency domain allows to separate the frequency
components of the signal, which can be thereby described as the sum of simple
waves, such as sine and cosine functions. Therefore, it is convenient to study
oscillatory behaviour with frequency analysis.

```{r}
compute_powers <- function(time_series) {
  
  powers <- fft(time_series)
  powers <- as.numeric(powers * Conj(powers))[2:(1 + length(powers) / 2)]
  norm_powers <- powers / sum(powers)
  
  return(norm_powers)
}
```

```{r}
power_mat <- t(apply(circ_mat, 1, compute_powers))
sorted_powers <- sort(power_mat[ , 2], decreasing = TRUE)
head(sorted_powers, 10)
```

```{r}
sum(is.na(sorted_powers))
```

# Part 6

```{r}
# Compute log statistics of each gene with custom function from part 2
circ_stats <- find_log_stats(circ_mat, na.rm = TRUE)
```

The genes are binned by similarity in library size and a z-score is calculated
within each bin. The top 40 genes with the highest z-score are then inspected to
understand their relation with circadian rhythms.

```{r}
library(dplyr)
library(tibble)

# Bin genes and compute their z-score
zscore_df <- circ_stats %>%
  rownames_to_column("GeneSymbol") %>%
  filter(Mean >= 3) %>%
  mutate(Bin = ntile(Mean, 20)) %>%
  group_by(Bin) %>%
  mutate(ZScore = (Var - mean(Var)) / sd(Var)) %>%
  arrange(desc(ZScore))

# View genes sorted by z-score
knitr::kable(head(zscore_df, 40), digits = 2)
```

Several of the top 40 genes are involved in the absorption of calcium and the
formation of bones. Such processes are known to be linked to the concentration
of vitamin D in the body, which is produced upon exposure to sunlight.
Therefore, we conclude that the found top 40 genes indeed show relevant
oscillations with a period of 24 hours in relation with the circadian rhythms.
